# -*- coding: utf-8 -*-
"""[Klasifikasi] Submission Akhir BMLP_Muhammad Aziz Habiburrahim

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h02tYin2xqtV8wQbv38oxNRTcq9AX8OH

# **1. Import Library**

Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning.
"""

# import library
!pip install category_encoders
!pip install optuna
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import optuna
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report
from sklearn.model_selection import GridSearchCV
from sklearn.compose import ColumnTransformer, make_column_selector
from sklearn.pipeline import Pipeline
from category_encoders import TargetEncoder
from xgboost import XGBClassifier
from google.colab import drive
drive.mount('/content/drive')

"""# **2. Memuat Dataset dari Hasil Clustering**

Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame.
"""

# memuat dataset dari hasil clustering
df = pd.read_csv('/content/drive/My Drive/Course/Datasets/Dataset_inisiasi.csv')
df.head()

"""# **3. Data Splitting**

Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set).
"""

# data splitting
x = df.drop(columns='clusters')
y = df['clusters']
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)

"""# **4. Membangun Model Klasifikasi**

## **a. Membangun Model Klasifikasi**

Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.

Berikut adalah rekomendasi tahapannya.
1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).
2. Latih model menggunakan data latih.
"""

# membangun model klasifikasi
column_transformer = ColumnTransformer([
    ('Cat Encoder', TargetEncoder(), make_column_selector(dtype_exclude=np.number))
], remainder='passthrough')

rf_pipeline = Pipeline([
    ('Preprocessor', column_transformer),
    ('Model', RandomForestClassifier(random_state=42))
])

xgb_pipeline = Pipeline([
    ('Preprocessor', column_transformer),
    ('Model', XGBClassifier(random_state=42))
])

rf_pipeline.fit(x_train, y_train)
xgb_pipeline.fit(x_train, y_train)

"""Tulis narasi atau penjelasan algoritma yang Anda gunakan.

## **b. Evaluasi Model Klasifikasi**

Berikut adalah **rekomendasi** tahapannya.
1. Lakukan prediksi menggunakan data uji.
2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).
3. Buat confusion matrix untuk melihat detail prediksi benar dan salah.
"""

# evaluasi model klasifikasi
print('RF MODEL')
print(classification_report(y_test, rf_pipeline.predict(x_test)))
print()

print('XGB MODEL')
print(classification_report(y_test, xgb_pipeline.predict(x_test)))

# evaluasi model klasifikasi
# generate predictions
y_pred_rf = rf_pipeline.predict(x_test)
y_pred_xgb = xgb_pipeline.predict(x_test)

# create subplots
plt.figure(figsize=(12, 5))

# random forest confusion matrix
plt.subplot(1, 2, 1)
cm_rf = confusion_matrix(y_test, y_pred_rf)
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues',
            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
plt.title('Random Forest Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')

# XGBoost confusion matrix
plt.subplot(1, 2, 2)
cm_xgb = confusion_matrix(y_test, y_pred_xgb)
sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Oranges',
            xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))
plt.title('XGBoost Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')

plt.tight_layout()
plt.show()

"""Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya.

## **c. Tuning Model Klasifikasi (Optional)**

Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik
"""

# tuning model klasifikasi
def objective(trial):
    # define hyperparameter space
    params = {
        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),
        'subsample': trial.suggest_float('subsample', 0.6, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),
        'gamma': trial.suggest_float('gamma', 0, 0.5),
    }

    # create model dengan parameter yang diuji
    model = XGBClassifier(
        **params,
        random_state=42,
        eval_metric='mlogloss'
    )

    # buat pipeline
    pipeline = Pipeline([
        ('Preprocessor', column_transformer),
        ('Model', model)
    ])

    # fit model
    pipeline.fit(x_train, y_train)

    # prediksi dan hitung metric
    y_pred = pipeline.predict(x_test)
    return f1_score(y_test, y_pred, average='macro')

# create study dan lakukan optimasi
study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50)

# tampilkan parameter terbaik
print("Best parameters:", study.best_params)
print("Best F1-Score:", study.best_value)

"""## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**

Berikut adalah rekomendasi tahapannya.
1. Gunakan model dengan hyperparameter terbaik.
2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa.
"""

# evaluasi model klasifikasi setelah tuning (optional)
best_model = XGBClassifier(
    **study.best_params,
    random_state=42,
    eval_metric='mlogloss'
)

xgb_pipeline_tuned = Pipeline([
    ('Preprocessor', column_transformer),
    ('Model', best_model)
])

xgb_pipeline_tuned.fit(x_train, y_train)

print('XGB MODEL TUNED')
print(classification_report(y_test, xgb_pipeline_tuned.predict(x_test)))

"""## **e. Analisis Hasil Evaluasi Model Klasifikasi**

## **Perbandingan Hasil Evaluasi**
Berdasarkan hasil evaluasi model **XGBoost sebelum dan setelah tuning**, dapat disimpulkan bahwa **tidak ada perubahan signifikan dalam metrik evaluasi**. Berikut adalah perbandingan utama:

| **Metrik**       | **Sebelum Tuning** | **Setelah Tuning** |
|------------------|------------------|------------------|
| **Accuracy**     | 0.96              | 0.98             |
| **Precision (Kelas 2)** | 0.93       | 0.94       |
| **Recall (Kelas 2)**    | 0.96       | 0.99       |
| **F1-Score (Kelas 2)**  | 0.95       | 0.96       |
| **Macro Avg**    | 0.96              | 0.98              |
| **Weighted Avg** | 0.97              | 0.98              |

Dari tabel tersebut, **tuning tidak memberikan peningkatan performa yang signifikan** karena model sudah mencapai tingkat akurasi yang sangat tinggi sebelumnya.
"""